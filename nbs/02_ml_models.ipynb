{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ML Models\n",
        "\n",
        "> Machine learning models and training functions for customer conversion prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| default_exp ml_models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jdemlow/miniconda3/envs/sfml/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
            "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'snowflake.ml.modeling.distributors'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dict, Any, List, Optional\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodeling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributors\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBEstimator, XGBScalingConfig\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mml\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_connector\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataConnector\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msnowflake\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msnowpark\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdataframe\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataFrame\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'snowflake.ml.modeling.distributors'"
          ]
        }
      ],
      "source": [
        "#| export\n",
        "import numpy as np\n",
        "from typing import Dict, Any, List, Optional\n",
        "from transformers import pipeline\n",
        "from snowflake.ml.modeling.distributors.xgboost import XGBEstimator, XGBScalingConfig\n",
        "from snowflake.ml.data.data_connector import DataConnector\n",
        "from snowflake.snowpark.dataframe import DataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| export\n",
        "class ModelPredictor:\n",
        "    \"\"\"Zero-shot classification model for review quality prediction.\"\"\"\n",
        "    \n",
        "    def __init__(self, model_name: str = \"facebook/bart-large-mnli\",\n",
        "                 candidate_labels: List[str] = None):\n",
        "        \"\"\"Initialize the model predictor.\n",
        "        \n",
        "        Args:\n",
        "            model_name: HuggingFace model name for zero-shot classification\n",
        "            candidate_labels: List of labels for classification\n",
        "        \"\"\"\n",
        "        if candidate_labels is None:\n",
        "            candidate_labels = [\n",
        "                'detailed with specific information and experience', \n",
        "                'basic accurate information', \n",
        "                'generic brief with no details'\n",
        "            ]\n",
        "        \n",
        "        self.candidate_labels = candidate_labels\n",
        "        self.classifier = pipeline(\"zero-shot-classification\", model=model_name)\n",
        "\n",
        "    def __call__(self, batch: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Predict review quality for a batch of reviews.\n",
        "        \n",
        "        Args:\n",
        "            batch: Dictionary containing review text data\n",
        "            \n",
        "        Returns:\n",
        "            Updated batch with prediction results\n",
        "        \"\"\"\n",
        "        resp = self.classifier(batch[\"REVIEW_TEXT\"].tolist(), self.candidate_labels)\n",
        "\n",
        "        # Handle both resp and batch results\n",
        "        if isinstance(resp, dict):\n",
        "            raise ValueError(f\"Expected batch response, got {resp} for batch {batch['REVIEW_TEXT']}\")\n",
        "            \n",
        "        # Add results to batch\n",
        "        batch[\"REVIEW_QUALITY\"] = np.array([\n",
        "            result[\"labels\"][np.argmax(result[\"scores\"])] for result in resp\n",
        "        ])\n",
        "        \n",
        "        return batch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#| export\n",
        "def create_xgb_model(config: Dict[str, Any] = None) -> XGBEstimator:\n",
        "    \"\"\"Create and configure XGBoost estimator.\n",
        "    \n",
        "    Args:\n",
        "        config: Configuration dictionary with model parameters\n",
        "        \n",
        "    Returns:\n",
        "        Configured XGBEstimator\n",
        "    \"\"\"\n",
        "    if config is None:\n",
        "        params = {\n",
        "            \"eta\": 0.1,\n",
        "            \"max_depth\": 8,\n",
        "            \"min_child_weight\": 100,\n",
        "            \"tree_method\": \"hist\",\n",
        "        }\n",
        "        n_estimators = 50\n",
        "    else:\n",
        "        ml_config = config.get('ml', {}).get('models', {}).get('purchase_prediction', {})\n",
        "        params = {\n",
        "            \"eta\": ml_config.get('learning_rate', 0.1),\n",
        "            \"max_depth\": ml_config.get('max_depth', 8),\n",
        "            \"min_child_weight\": 100,\n",
        "            \"tree_method\": \"hist\",\n",
        "        }\n",
        "        n_estimators = ml_config.get('n_estimators', 50)\n",
        "    \n",
        "    scaling_config = XGBScalingConfig(use_gpu=False)\n",
        "    \n",
        "    estimator = XGBEstimator(\n",
        "        n_estimators=n_estimators,\n",
        "        objective=\"reg:squarederror\",\n",
        "        params=params,\n",
        "        scaling_config=scaling_config,\n",
        "    )\n",
        "    \n",
        "    return estimator\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "sfml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
